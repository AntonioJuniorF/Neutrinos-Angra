{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ojetivo deste código\n",
    "* Monitoramento temporal dos canais da NDAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.matlib \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "import timeit\n",
    "%matplotlib inline\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Váriaveis padrões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STS          = ['FlashADC_1','FlashADC_2','FlashADC_3','FlashADC_4','FlashADC_5','FlashADC_6','FlashADC_7','FlashADC_8']\n",
    "ST           = ['Slot_Number_6','Slot_Number_10','Slot_Number_12','Slot_Number_14','Slot_Number_16']\n",
    "Num_NDAQ     = [6,10,12,14,16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contron_pac(mes):\n",
    "\n",
    "\n",
    "    dia       = []\n",
    "    cont_MES  = []\n",
    "    cont0     = []\n",
    "    diretorio = [\"/data2/raw/*\",\"/data3/raw/*\"]\n",
    "    ref1      = ['/data2/raw/AngraRun_T','/data3/raw/AngraRun_T']\n",
    "\n",
    "    for j in range(len(diretorio)):\n",
    "        List = glob.glob(diretorio[j]) # listando todos os dados\n",
    "        for i in range(len(List)):\n",
    "            if List[i][0:21] != ref1[j]:\n",
    "                cont0.append(List[i])\n",
    "        for i in range(len(cont0)):\n",
    "            ts = int(np.array(cont0)[i][20:-8])\n",
    "            datas  = (datetime.fromtimestamp(ts).strftime('%Y-%m-%d'))\n",
    "            if datas[0:4] == '2019':\n",
    "                if datas[5:7] == mes:\n",
    "                    cont_MES.append(cont0[i])\n",
    "                    if datas[8] == '0':\n",
    "                        dia.append(datas[9])\n",
    "                    if datas[8] == '1':\n",
    "                        dia.append(datas[8:10])\n",
    "                    if datas[8] == '2':\n",
    "                        dia.append(datas[8:10])\n",
    "                    if datas[8] == '3':\n",
    "                        dia.append(datas[8:10])\n",
    "      \n",
    "    return cont_MES,dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_ndaqs(ind1,ind2):\n",
    "    ndaq6 = np.where((ind1.values.T[0] ==6))[0]\n",
    "    ndaq10 = np.where((ind1.values.T[0] ==10))[0]\n",
    "    ndaq12 = np.where((ind1.values.T[0] ==12))[0]\n",
    "    ndaq14 = np.where((ind1.values.T[0] ==14))[0]\n",
    "    return ndaq6[:-1], ndaq10[:-1], ndaq12[:-1], ndaq14[:-1]\n",
    "\n",
    "def align_data(ndaq6, ndaq10, ndaq12, ndaq14,time):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 0\n",
    "    l = 0\n",
    "    aligned6 = []\n",
    "    aligned10 = []\n",
    "    aligned12 = []\n",
    "    aligned14 = []\n",
    "    \n",
    "    slot6  = time['Timestamp'][ndaq6][1:]\n",
    "    slot10 = time['Timestamp'][ndaq10][1:]\n",
    "    slot12 = time['Timestamp'][ndaq12][1:]\n",
    "    slot14 = time['Timestamp'][ndaq14][1:]\n",
    "    \n",
    "    for i in range(0,len(slot6)):\n",
    "        value = slot6[slot6.index[i]]\n",
    "        max_distortion = max(5,150*value/1000000)\n",
    "        no_j = 0\n",
    "        no_k = 0\n",
    "        no_l = 0\n",
    "        range_0 = min(20,len(slot10)-j)\n",
    "        for m in range(j,j+range_0):\n",
    "            if (abs(value - slot10[slot10.index[m]]))<max_distortion:\n",
    "                j=m+1\n",
    "                break\n",
    "            if (m==j+range_0-1):\n",
    "                no_j = 1\n",
    "                break\n",
    "        if range_0==0:\n",
    "            no_j=1\n",
    "        range_1 = min(20,len(slot12)-k)\n",
    "        for m in range(k,k+range_1):\n",
    "            if (abs(value - slot12[slot12.index[m]]))<max_distortion:\n",
    "                k=m+1\n",
    "                break\n",
    "            if (m==k+range_1-1):\n",
    "                no_k = 1\n",
    "                break\n",
    "        if range_1==0:\n",
    "            no_k=1        \n",
    "        range_2 = min(20,len(slot14)-l)\n",
    "        for m in range(l,l+range_2):\n",
    "            if (abs(value - slot14[slot14.index[m]]))<max_distortion:\n",
    "                l=m+1\n",
    "                break\n",
    "            if (m==l+range_2-1):\n",
    "                no_l = 1\n",
    "                break\n",
    "        if range_2==0:\n",
    "            no_l=1\n",
    "        \n",
    "        si = slot6.index[i]\n",
    "        sj = slot10.index[j-1]\n",
    "        sk = slot12.index[k-1]\n",
    "        sl = slot14.index[l-1]\n",
    "        if (no_j == 0) and (no_k == 0) and (no_l == 0):\n",
    "            aligned6.append(si)\n",
    "            aligned10.append(sj)\n",
    "            aligned12.append(sk)\n",
    "            aligned14.append(sl)\n",
    "    return aligned6, aligned10, aligned12, aligned14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_PMT(pac,STS,thr):\n",
    "    ind1 = pd.read_parquet(pac, columns=['Slot Number'])\n",
    "\n",
    "    ind2 = pd.read_parquet(pac, columns=['BusyFlag'])\n",
    "    time = pd.read_parquet(pac,columns=['Timestamp'])\n",
    "    ndaq6, ndaq10, ndaq12, ndaq14=separate_ndaqs(ind1,ind2)\n",
    "    \n",
    "    #aligned6, aligned10, aligned12, aligned14 = align_data(ndaq6, ndaq10, ndaq12, ndaq14,time) \n",
    "   \n",
    "    aligned6 = ndaq6\n",
    "    aligned10 = ndaq10\n",
    "    aligned12 = ndaq12\n",
    "    aligned14 = ndaq14\n",
    "\n",
    "    CNDAQ6  = np.zeros((len(aligned6),8))\n",
    "    CNDAQ10 = np.zeros((len(aligned10),8))\n",
    "    CNDAQ12 = np.zeros((len(aligned12),8))\n",
    "    CNDAQ14 = np.zeros((len(aligned14),8))\n",
    "\n",
    "    ANDAQ6  = np.zeros((len(aligned6),8))\n",
    "    ANDAQ10 = np.zeros((len(aligned10),8))\n",
    "    ANDAQ12 = np.zeros((len(aligned12),8))\n",
    "    ANDAQ14 = np.zeros((len(aligned14),8))\n",
    "\n",
    "    PNDAQ6  = np.zeros((len(aligned6),8))\n",
    "    PNDAQ10 = np.zeros((len(aligned10),8))\n",
    "    PNDAQ12 = np.zeros((len(aligned12),8))\n",
    "    PNDAQ14 = np.zeros((len(aligned14),8))\n",
    "\n",
    "\n",
    "    mask = np.array([1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "    for i in range(len(STS)):\n",
    "        df         = pd.read_parquet(pac, columns=[STS[i]])\n",
    "        \n",
    "        S6         = np.stack(df.loc[aligned6]['FlashADC_'+str(1+i)])\n",
    "        S10        = np.stack(df.loc[aligned10]['FlashADC_'+str(1+i)])\n",
    "        S12        = np.stack(df.loc[aligned12]['FlashADC_'+str(1+i)])\n",
    "        S14        = np.stack(df.loc[aligned14]['FlashADC_'+str(1+i)])\n",
    "        \n",
    "        del df\n",
    "        #timestamp1 = np.array(time.loc[aligned6]['Timestamp'])\n",
    "        \n",
    "        baseline6  = np.dot(S6,mask)/mask.sum()\n",
    "        baseline10 = np.dot(S10,mask)/mask.sum()\n",
    "        baseline12 = np.dot(S12,mask)/mask.sum()\n",
    "        baseline14 = np.dot(S14,mask)/mask.sum()\n",
    "       \n",
    "        Amp6  = baseline6\n",
    "        Amp10 = baseline10\n",
    "        Amp12 = baseline12\n",
    "        Amp14 = baseline14\n",
    "        \n",
    "        sat6  = np.argmax(S6,  axis =1)\n",
    "        sat10 = np.argmax(S10, axis =1)\n",
    "        sat12 = np.argmax(S12, axis =1)\n",
    "        sat14 = np.argmax(S14, axis =1)\n",
    "\n",
    "        #Carga6  = np.sum(S6,   axis =1)  - baseline6*S6.shape[1]\n",
    "        #Carga10 = np.sum(S10,  axis =1)  - baseline10*S10.shape[1]\n",
    "        #Carga12 = np.sum(S12,  axis =1)  - baseline12*S12.shape[1]\n",
    "        #Carga14 = np.sum(S14,  axis =1)  - baseline14*S14.shape[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        Carga6  = np.max(S6,   axis =1)  - baseline6\n",
    "        Carga10 = np.max(S10,  axis =1)  - baseline10\n",
    "        Carga12 = np.max(S12,  axis =1)  - baseline12\n",
    "        Carga14 = np.max(S14,  axis =1)  - baseline14\n",
    "        \n",
    "        \n",
    "      \n",
    "        Amp6[Carga6<0]   = 0\n",
    "        Amp10[Carga10<0] = 0\n",
    "        Amp12[Carga12<0] = 0\n",
    "        Amp14[Carga14<0] = 0\n",
    "\n",
    "        Carga6[Carga6<0]   = 0\n",
    "        Carga10[Carga10<0] = 0\n",
    "        Carga12[Carga12<0] = 0\n",
    "        Carga14[Carga14<0] = 0\n",
    "\n",
    "        CNDAQ6[:,0 +i]  = Carga6\n",
    "        CNDAQ10[:,0 +i] = Carga10\n",
    "        CNDAQ12[:,0+i]  = Carga12\n",
    "        CNDAQ14[:,0+i]  = Carga14\n",
    "\n",
    "        ANDAQ6[:,0 +i]  = Amp6\n",
    "        ANDAQ10[:,0 +i] = Amp10\n",
    "        ANDAQ12[:,0+i]  = Amp12\n",
    "        ANDAQ14[:,0+i]  = Amp14\n",
    "\n",
    "        PNDAQ6[:,0 +i]  = sat6\n",
    "        PNDAQ10[:,0 +i] = sat10\n",
    "        PNDAQ12[:,0+i]  = sat12\n",
    "        PNDAQ14[:,0+i]  = sat14\n",
    "        \n",
    "        Cmatrix      = np.concatenate((CNDAQ6,CNDAQ10,CNDAQ12,CNDAQ14), axis =1)\n",
    "        Amatrix      = np.concatenate((ANDAQ6,ANDAQ10,ANDAQ12,ANDAQ14), axis =1)\n",
    "        Pmatrix      = np.concatenate((PNDAQ6,PNDAQ10,PNDAQ12,PNDAQ14), axis =1)\n",
    "    \n",
    "    return Cmatrix,Amatrix,Pmatrix\n",
    "\n",
    "def data_flame_dados(pac0):\n",
    "    Cmatrix,Amatrix,Pmatrix = cont_PMT(pac0,STS,8)\n",
    "    \n",
    "    matrix = np.concatenate((Cmatrix.T,Amatrix.T,Pmatrix.T), axis = 0).T\n",
    "    col=['PMT01','PMT02','PMT03', 'PMT04','PMT05','PMT06','PMT07','PMT08','PMT09','PMT10',\n",
    "         'PMT11','PMT12','PMT13', 'PMT14','PMT15','PMT16','PMT17','PMT18','PMT19','PMT20',\n",
    "         'PMT21','PMT22','PMT23', 'PMT24','PMT25','PMT26','PMT27','PMT28','PMT29','PMT30',\n",
    "         'PMT31','PMT32','PMT01_p','PMT02_p','PMT03_p', 'PMT04_p','PMT05_p','PMT06_p','PMT07_p','PMT08_p','PMT09_p','PMT10_p',\n",
    "         'PMT11_p','PMT12_p','PMT13_p','PMT14_p','PMT15_p','PMT16_p','PMT17_p','PMT18_p','PMT19_p','PMT20_p',\n",
    "         'PMT21_p','PMT22_p','PMT23_p','PMT24_p','PMT25_p','PMT26_p','PMT27_p','PMT28_p','PMT29_p','PMT30_p',\n",
    "         'PMT31_p','PMT32_p','PMT01_m','PMT02_m','PMT03_m','PMT04_m','PMT05_m','PMT06_m','PMT07_m','PMT08_m','PMT09_m','PMT10_m',\n",
    "         'PMT11_m','PMT12_m','PMT13_m','PMT14_m','PMT15_m','PMT16_m','PMT17_m','PMT18_m','PMT19_m','PMT20_m',\n",
    "         'PMT21_m','PMT22_m','PMT23_m', 'PMT24_m','PMT25_m','PMT26_m','PMT27_m','PMT28_m','PMT29_m','PMT30_m',\n",
    "         'PMT31_m','PMT32_m']\n",
    "    df = pd.DataFrame(matrix,columns=col, dtype='int32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_std(df,df1,df2,df3,df4,col):\n",
    "    a = df[col]\n",
    "    b = df1[col]\n",
    "    c = df2[col]\n",
    "    d = df3[col]\n",
    "    e = df4[col]\n",
    "    #f = df5[col]\n",
    "    \n",
    "    matrix = np.concatenate((a,b,c,d,e))\n",
    "    media  = np.mean(matrix, axis = 0)\n",
    "    STD    =  np.std(matrix, axis = 0)\n",
    "    \n",
    "    return media, STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dados (pac):\n",
    "    df  = data_flame_dados(pac[0])\n",
    "    df1 = data_flame_dados(pac[1])\n",
    "    df2 = data_flame_dados(pac[2])\n",
    "    df3 = data_flame_dados(pac[3])\n",
    "    df4 = data_flame_dados(pac[4])\n",
    "    #df5 = data_flame_dados(pac[5])\n",
    "\n",
    "    carga,    c_std = media_std(df,df1,df2,df3,df4,col_a)\n",
    "    pedestal, p_std = media_std(df,df1,df2,df3,df4,col_b)\n",
    "    amostra,  a_std = media_std(df,df1,df2,df3,df4,col_c)\n",
    "    return carga, c_std ,pedestal, p_std,amostra,a_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando os arquivos no mês que eu quero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mes = '01'\n",
    "cont_MES,dia = contron_pac(mes) # pacotes que estão neste mês e os dias que o pacote representa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia  = np.array(dia)\n",
    "cont_MES = np.array(cont_MES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponteiro_dia = np.sort(np.int64(np.unique(dia)))\n",
    "ind_d        = np.arange(0,len(np.unique(dia)),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ind_d)):\n",
    "    pac = np.array(cont_MES)[dia == str(ponteiro_dia[ind_d][i])]\n",
    "    pac = np.unique(pac)\n",
    "    #ind = np.arange(0,len(pac),round(len(pac)/6))\n",
    "    ind = np.arange(6)\n",
    "    #pac0 = pac[ind]\n",
    "    if len(pac) < 40:\n",
    "        relatorio[i] = 1 \n",
    "        print('a')\n",
    "    else:\n",
    "        for j in range(len(ind)):\n",
    "            for k in range(5):\n",
    "                pac0 = pac[ind[j] + k]\n",
    "                df         = pd.read_parquet(pac[ind[j]], columns=[STS[0]])\n",
    "                if df.shape[0] == 0:\n",
    "                    print(b)\n",
    "                    relatorio[i,j] = 1\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum(np.sum(relatorio,axis = 1) > 0) >0:\n",
    "    ind_delet = np.where(np.sum(relatorio,axis = 1) > 0)[0][0]\n",
    "    ind_d = np.delete(ind_d,ind_delet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_a = ['PMT01','PMT02','PMT03', 'PMT04','PMT05','PMT06','PMT07','PMT08','PMT09','PMT10',\n",
    "         'PMT11','PMT12','PMT13', 'PMT14','PMT15','PMT16','PMT17','PMT18','PMT19','PMT20',\n",
    "         'PMT21','PMT22','PMT23', 'PMT24','PMT25','PMT26','PMT27','PMT28','PMT29','PMT30',\n",
    "         'PMT31','PMT32']\n",
    "\n",
    "col_as = ['PMT01s','PMT02s','PMT03s','PMT04s','PMT05s','PMT06s','PMT07s','PMT08s','PMT09s','PMT10s',\n",
    "          'PMT11s','PMT12s','PMT13s','PMT14s','PMT15s','PMT16s','PMT17s','PMT18s','PMT19s','PMT20s',\n",
    "          'PMT21s','PMT22s','PMT23s','PMT24s','PMT25s','PMT26s','PMT27s','PMT28s','PMT29s','PMT30s',\n",
    "          'PMT31s','PMT32s']\n",
    "\n",
    "col_b = ['PMT01_p','PMT02_p','PMT03_p', 'PMT04_p','PMT05_p','PMT06_p','PMT07_p','PMT08_p','PMT09_p','PMT10_p',\n",
    "         'PMT11_p','PMT12_p','PMT13_p','PMT14_p','PMT15_p','PMT16_p','PMT17_p','PMT18_p','PMT19_p','PMT20_p',\n",
    "         'PMT21_p','PMT22_p','PMT23_p','PMT24_p','PMT25_p','PMT26_p','PMT27_p','PMT28_p','PMT29_p','PMT30_p',\n",
    "         'PMT31_p','PMT32_p']\n",
    "\n",
    "col_bs = ['PMT01_ps','PMT02_ps','PMT03_ps','PMT04_ps','PMT05_ps','PMT06_ps','PMT07_ps','PMT08_ps','PMT09_ps','PMT10_ps',\n",
    "          'PMT11_ps','PMT12_ps','PMT13_ps','PMT14_ps','PMT15_ps','PMT16_ps','PMT17_ps','PMT18_ps','PMT19_ps','PMT20_ps',\n",
    "          'PMT21_ps','PMT22_ps','PMT23_ps','PMT24_ps','PMT25_ps','PMT26_ps','PMT27_ps','PMT28_ps','PMT29_ps','PMT30_ps',\n",
    "          'PMT31_ps','PMT32_ps']\n",
    "\n",
    "col_c = ['PMT01_m','PMT02_m','PMT03_m','PMT04_m','PMT05_m','PMT06_m','PMT07_m','PMT08_m','PMT09_m','PMT10_m',\n",
    "         'PMT11_m','PMT12_m','PMT13_m','PMT14_m','PMT15_m','PMT16_m','PMT17_m','PMT18_m','PMT19_m','PMT20_m',\n",
    "         'PMT21_m','PMT22_m','PMT23_m','PMT24_m','PMT25_m','PMT26_m','PMT27_m','PMT28_m','PMT29_m','PMT30_m',\n",
    "         'PMT31_m','PMT32_m']\n",
    "\n",
    "col_cs = ['PMT01_ms','PMT02_ms','PMT03_ms','PMT04_ms','PMT05_ms','PMT06_ms','PMT07_ms','PMT08_ms','PMT09_ms','PMT10_ms',\n",
    "         'PMT11_ms','PMT12_ms','PMT13_ms','PMT14_ms','PMT15_ms','PMT16_ms','PMT17_ms','PMT18_ms','PMT19_ms','PMT20_ms',\n",
    "         'PMT21_ms','PMT22_ms','PMT23_ms','PMT24_ms','PMT25_ms','PMT26_ms','PMT27_ms','PMT28_ms','PMT29_ms','PMT30_ms',\n",
    "         'PMT31_ms','PMT32_ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "coluna = np.concatenate((col_a,col_as,col_b,col_bs,col_c,col_cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "DUQm = []\n",
    "DUQstd =[]\n",
    "PEDm = []\n",
    "PEDs =[]\n",
    "AMOm =[]\n",
    "AMOs = []\n",
    "DIA  = []\n",
    "\n",
    "for i in range(len(ind_d)):\n",
    "    pac = np.array(cont_MES)[dia == str(ponteiro_dia[ind_d][i])]\n",
    "    pac = np.unique(pac)\n",
    "    ind = np.arange(6)\n",
    "    #ind = np.arange(0,len(pac),round(len(pac)/6))\n",
    "    pac = pac[ind]\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "    carga, c_std ,pedestal, p_std,amostra,a_std = dados(pac)\n",
    "    DUQm.append(carga)\n",
    "    DUQstd.append(c_std)\n",
    "\n",
    "    PEDm.append(pedestal)\n",
    "    PEDs.append(p_std)\n",
    "\n",
    "    AMOm.append(amostra)\n",
    "    AMOs.append(a_std)\n",
    "\n",
    "    DIA.append(ponteiro_dia[ind_d][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUQm   = np.stack(DUQm)\n",
    "DUQstd = np.stack(DUQstd)\n",
    "\n",
    "AMOm = np.stack(AMOm)\n",
    "AMOs = np.stack(AMOm)\n",
    "\n",
    "PEDm = np.stack(PEDm)\n",
    "PEDs = np.stack(PEDs)\n",
    "\n",
    "DIA = np.stack(DIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.arange(1,32) # Dias do mês de abril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDAQ_C  = np.zeros((len(D),32))\n",
    "NDAQ_Cs = np.zeros((len(D),32))\n",
    "NDAQ_P  = np.zeros((len(D),32))\n",
    "NDAQ_Ps = np.zeros((len(D),32))\n",
    "NDAQ_A  = np.zeros((len(D),32))\n",
    "NDAQ_As = np.zeros((len(D),32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDAQ_C[DIA-1]  = DUQm\n",
    "NDAQ_Cs[DIA-1] = DUQstd\n",
    "\n",
    "NDAQ_P[DIA-1]  = PEDm\n",
    "NDAQ_Ps[DIA-1] = PEDs\n",
    "\n",
    "NDAQ_A[DIA-1]  = AMOm\n",
    "NDAQ_As[DIA-1] = AMOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDAQ_C[NDAQ_C == 0] = np.NAN\n",
    "NDAQ_Cs[NDAQ_Cs == 0] = np.NAN\n",
    "\n",
    "NDAQ_P[NDAQ_P == 0] = np.NAN\n",
    "NDAQ_Ps[NDAQ_Ps == 0] = np.NAN\n",
    "\n",
    "NDAQ_A[NDAQ_A == 0] = np.NAN\n",
    "NDAQ_As[NDAQ_As == 0] = np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.concatenate((NDAQ_C,NDAQ_Cs,NDAQ_P,NDAQ_Ps,NDAQ_A,NDAQ_As), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(matrix,columns=coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('Jan_va.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
